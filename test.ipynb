{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                              title  \\\n",
      "0  304586  The WASA2 object-oriented workflow management ...   \n",
      "1  304587  A user-centered interface for querying distrib...   \n",
      "2  304589  World Wide Database-integrating the Web, CORBA...   \n",
      "3  304590           XML-based information mediation with MIX   \n",
      "4  304582  The CCUBE constraint object-oriented database ...   \n",
      "\n",
      "                                             authors  \\\n",
      "0                    Gottfried Vossen, Mathias Weske   \n",
      "1                  Isabel F. Cruz, Kimberly M. James   \n",
      "2  Athman Bouguettaya, Boualem Benatallah, Lily H...   \n",
      "3  Chaitan Baru, Amarnath Gupta, Bertram Lud&#228...   \n",
      "4  Alexander Brodsky, Victor E. Segal, Jia Chen, ...   \n",
      "\n",
      "                                            venue  year  \n",
      "0  International Conference on Management of Data  1999  \n",
      "1  International Conference on Management of Data  1999  \n",
      "2  International Conference on Management of Data  1999  \n",
      "3  International Conference on Management of Data  1999  \n",
      "4  International Conference on Management of Data  1999  \n",
      "                       authors  \\\n",
      "0             Gottfried Vossen   \n",
      "0                Mathias Weske   \n",
      "1               Isabel F. Cruz   \n",
      "1            Kimberly M. James   \n",
      "2           Athman Bouguettaya   \n",
      "...                        ...   \n",
      "2290        Raghu Ramakrishnan   \n",
      "2291  Ralf Hartmut G&#252;ting   \n",
      "2292     Alexander A. Anisimov   \n",
      "2293           Janet L. Wiener   \n",
      "2293       Jeffrey F. Naughton   \n",
      "\n",
      "                                                  venue  \\\n",
      "0        International Conference on Management of Data   \n",
      "0        International Conference on Management of Data   \n",
      "1        International Conference on Management of Data   \n",
      "1        International Conference on Management of Data   \n",
      "2        International Conference on Management of Data   \n",
      "...                                                 ...   \n",
      "2290  The VLDB Journal &mdash; The International Jou...   \n",
      "2291                              Very Large Data Bases   \n",
      "2292                                 ACM SIGMOD Record    \n",
      "2293                              Very Large Data Bases   \n",
      "2293                              Very Large Data Bases   \n",
      "\n",
      "                                                  title  \n",
      "0     The WASA2 object-oriented workflow management ...  \n",
      "0     The WASA2 object-oriented workflow management ...  \n",
      "1     A user-centered interface for querying distrib...  \n",
      "1     A user-centered interface for querying distrib...  \n",
      "2     World Wide Database-integrating the Web, CORBA...  \n",
      "...                                                 ...  \n",
      "2290                                    Guest editorial  \n",
      "2291  GraphDB: Modeling and Querying Graphs in Datab...  \n",
      "2292  Review of The data warehouse toolkit: the comp...  \n",
      "2293     Bulk Loading into an OODB: A Performance Study  \n",
      "2293     Bulk Loading into an OODB: A Performance Study  \n",
      "\n",
      "[6839 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df= pd.read_csv(r'C:\\Users\\Zain\\Downloads\\ACM.csv')\n",
    "print(df.head())\n",
    "df['authors'] = df['authors'].str.split(', ')\n",
    "\n",
    "# Explode the 'Authors' column to create separate rows for each author\n",
    "df_exploded = df.explode('authors')\n",
    "\n",
    "# Reorder columns for clarity (optional)\n",
    "df_exploded = df_exploded[['authors', 'venue', 'title']]\n",
    "\n",
    "print(df_exploded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def normalize(matrix):\n",
    "    row_sums = matrix.sum(axis=1)\n",
    "    return matrix / row_sums[:, np.newaxis]\n",
    "\n",
    "def random_walk_with_restart(adjacency_matrix, start_node, restart_prob, tolerance):\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "    current_scores = np.zeros(num_nodes)\n",
    "    current_scores[start_node] = 1.0\n",
    "\n",
    "    while True:\n",
    "        next_scores = (1 - restart_prob) * np.dot(adjacency_matrix, current_scores) + restart_prob * current_scores\n",
    "\n",
    "        \n",
    "        if np.linalg.norm(next_scores - current_scores) < tolerance:\n",
    "            break\n",
    "\n",
    "        current_scores = next_scores\n",
    "\n",
    "    return current_scores\n",
    "\n",
    "def compute_relevance_scores(graph_matrix, start_node, restart_prob=0.15, tolerance=0.1):\n",
    "    num_nodes = graph_matrix.shape[0]\n",
    "\n",
    "    \n",
    "    norm_matrix = normalize(graph_matrix)\n",
    "\n",
    "    \n",
    "    relevance_scores = random_walk_with_restart(norm_matrix, start_node, restart_prob, tolerance)\n",
    "\n",
    "    return relevance_scores\n",
    "\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\Zain\\Downloads\\ACM.csv')\n",
    "data['authors'] = data['authors'].str.split(', ')\n",
    "\n",
    "\n",
    "df = data.explode('authors').reset_index(drop=True)\n",
    "\n",
    "\n",
    "df = df[['authors', 'venue', 'title']]\n",
    "\n",
    "# Sample data columns\n",
    "conference_column = 'venue'\n",
    "author_column = 'authors'\n",
    "topic_column = 'title' \n",
    "\n",
    "\n",
    "G_bipartite = nx.Graph()\n",
    "G_bipartite.add_nodes_from(df[conference_column].unique(), bipartite=0)\n",
    "G_bipartite.add_nodes_from(df[author_column].unique(), bipartite=1)\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    G_bipartite.add_edge(row[conference_column], row[author_column], weight=1)\n",
    "\n",
    "\n",
    "G_tripartite = nx.Graph()\n",
    "G_tripartite.add_nodes_from(df[conference_column].unique(), bipartite=0)\n",
    "G_tripartite.add_nodes_from(df[author_column].unique(), bipartite=1)\n",
    "G_tripartite.add_nodes_from(df[topic_column].unique(), bipartite=2)\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    G_tripartite.add_edge(row[conference_column], row[author_column], weight=1)\n",
    "    G_tripartite.add_edge(row[author_column], row[topic_column], weight=1)\n",
    "\n",
    "\n",
    "graph_matrix_bipartite = nx.to_numpy_array(G_bipartite)\n",
    "graph_matrix_tripartite = nx.to_numpy_array(G_tripartite)\n",
    "\n",
    "\n",
    "class AuthorPageApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Author Page\")\n",
    "\n",
    "        \n",
    "        self.create_widgets()\n",
    "\n",
    "    def create_widgets(self):\n",
    "        \n",
    "        self.label_author = ttk.Label(self.root, text=\"Enter author's name:\")\n",
    "        self.entry_author = ttk.Entry(self.root, width=30)\n",
    "\n",
    "       \n",
    "        self.button_get_page = ttk.Button(self.root, text=\"Get Author Page\", command=self.get_author_page)\n",
    "\n",
    "        self.result_text = tk.Text(self.root, height=10, width=80, state=tk.DISABLED)\n",
    "\n",
    "        \n",
    "        self.label_author.grid(row=0, column=0, padx=10, pady=5, sticky=tk.E)\n",
    "        self.entry_author.grid(row=0, column=1, padx=10, pady=5, sticky=tk.W)\n",
    "        self.button_get_page.grid(row=1, column=0, columnspan=2, pady=10)\n",
    "        self.result_text.grid(row=2, column=0, columnspan=2, padx=10, pady=5)\n",
    "\n",
    "    def get_author_page(self):\n",
    "        author_name = self.entry_author.get()\n",
    "\n",
    "        try:\n",
    "            \n",
    "            author_index = df[author_column].tolist().index(author_name)\n",
    "\n",
    "           \n",
    "            relevance_scores_bipartite = compute_relevance_scores(graph_matrix_bipartite, author_index)\n",
    "\n",
    "            \n",
    "            coauthor_indices = np.argsort(relevance_scores_bipartite)[-6:-1]\n",
    "            coauthors = set(df.iloc[coauthor_indices][author_column])\n",
    "\n",
    "           \n",
    "            result_text = f\"Author: {author_name}\\n\\n\"\n",
    "            result_text += f\"Unique Co-authors:\\n{', '.join(coauthors)}\\n\\n\"\n",
    "\n",
    "            \n",
    "            for coauthor in coauthors:\n",
    "                coauthor_index = df[author_column].tolist().index(coauthor)\n",
    "                coauthored_topic_indices = np.nonzero(graph_matrix_tripartite[author_index, coauthor_index + df[conference_column].nunique():])[0]\n",
    "                coauthored_topics = df.iloc[coauthored_topic_indices]\n",
    "                \n",
    "               \n",
    "                for _, coauthored_topic in coauthored_topics.iterrows():\n",
    "                    result_text += f\"{coauthor} ({coauthored_topic[conference_column]}): {coauthored_topic[topic_column]}\\n\"\n",
    "\n",
    "\n",
    "            self.result_text.config(state=tk.NORMAL)\n",
    "            self.result_text.delete(1.0, tk.END)\n",
    "            self.result_text.insert(tk.END, result_text)\n",
    "            self.result_text.config(state=tk.DISABLED)\n",
    "        except ValueError:\n",
    "           \n",
    "            self.result_text.config(state=tk.NORMAL)\n",
    "            self.result_text.delete(1.0, tk.END)\n",
    "            self.result_text.insert(tk.END, f\"Error: Author '{author_name}' not found\")\n",
    "            self.result_text.config(state=tk.DISABLED)\n",
    "\n",
    "\n",
    "root = tk.Tk()\n",
    "app = AuthorPageApp(root)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
